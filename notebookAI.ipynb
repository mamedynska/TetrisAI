{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Exemple d'avant :\n",
    "\n",
    "# # Premier réseau de neuronnes : reconnaissances d'un chiffre écrit à la main :\n",
    "\n",
    "# # Les deux jeux de données sont des jeu de données connues et utilisé pour apprendre les NN, on les téléchargent directement grâce au download=True, \n",
    "# #  On les téléchargent dans le répertoire du premier paramètre de MNIST ici : ''\n",
    "\n",
    "# # Jeu de données pour l'apprentissage\n",
    "# train = datasets.MNIST('', train=True, download=True,\n",
    "#                        transform=transforms.Compose([\n",
    "#                            transforms.ToTensor()\n",
    "#                        ]))\n",
    "# # Jeu de données pour les tests\n",
    "# test = datasets.MNIST('', train=False, download=True,\n",
    "#                        transform=transforms.Compose([\n",
    "#                            transforms.ToTensor()\n",
    "#                        ]))\n",
    "\n",
    "# # On mélange les données et batch_size c'est combien de données à la fois on passe mais comme on va traiter des images de 28*28, nos CPU pouuraient tous traiter d'un coup\n",
    "# trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "# testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=False)\n",
    "\n",
    "# # La classe qui représente le réseau de neuronnes, elle hérites de nn.Module\n",
    "# class Net(nn.Module):\n",
    "\n",
    "# # On utilise init de nn.Module avec super()\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         input = 28*28\n",
    "#         output = output2 = output3 = 64\n",
    "#         lastOutput = 10         # On veut reconnaître des chiffres donc la dernière sortie sera entre [0,9] donc de tailles 10\n",
    "\n",
    "#         # On créer nos couches de neuronnes\n",
    "#         self.fc1 = nn.Linear(input, output)         # Nb input = le nombre de valeur à prendre en compte pour la décision \n",
    "#                                                     # Nb output le nombre de choix possible pour une décision\n",
    "#         self.fc2 = nn.Linear(output, output2)       # 1Deuxième couche de neuronnes\n",
    "#         self.fc3 = nn.Linear(output2, output3)      # Troisième : Possibilité que output=output2=output3\n",
    "#         self.fc4 = nn.Linear(output3, lastOutput)\n",
    "\n",
    "\n",
    "# # Pour chaque données on l'a fait passer à travers notre réseau de neuronnes\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.fc1(x))         # F.relu transforme notre x (qui peut être = 15605 par ex) dans un intervalle [0,1]\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = F.relu(self.fc3(x))\n",
    "#         x = self.fc4(x)                 # Pour notre dernière couche qui sera une matrice de taille [1, nb de coup jouable] \n",
    "\n",
    "#         return F.log_softmax(x, dim=1)  #On aura une matrice de taille 1,10 pour la reconnaissance des chiffres avec une probabilité que ce soit chacun des chiffres\n",
    "\n",
    "# # Ici c'est mon main hihi\n",
    "# net = Net()\n",
    "# # print(net)\n",
    "\n",
    "# # x = torch.rand((1,10))\n",
    "# # print(x)\n",
    "# # x = x.view(1,10)\n",
    "# # output=net(x)\n",
    "# # print(output)\n",
    "\n",
    "# loss_function = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(net.parameters(), lr=0.001)      # lr = learning rate : permet de dire à l'optimizer de ne pas sur apprendre sur chaque données\n",
    "#                                                         # On ne va pas que lorsqu'il se trompe dans sa prédiction, il se corrige pour avoir une probabilité de 0 partout et de 1 sur le bon chiffre\n",
    "#                                                         # Sinon on va sur-apprendre et ce n'est pas bon\n",
    "#                                                         # On va donc optimiser la perte \"Loss\" sans la rendre nulle pour éviter le sur-apprentissage\n",
    "# EPOCHS = 3\n",
    "# for epoch in range(EPOCHS): # 3 full passes over the data\n",
    "#     for data in trainset:  # `data` is a batch of data\n",
    "#          X, y = data  # X sont les données d'une image 28*28, y est le label càd le chiffre que représente l'image\n",
    "#          net.zero_grad()    # On reset pour chaque data\n",
    "#          output = net(X.view(-1,28*28))  # On fait passer notre data dans le NN (-1 pour faire ligne --> colonne)\n",
    "#          loss = F.nll_loss(output, y)   # On calcul la perte avec l'output qu'on a eu et y le résultat voulu\n",
    "#          loss.backward()                # Calcul tous seul le gradient (merci Pytorch)     \n",
    "#          optimizer.step()               # Lance une étape d'optimisatin\n",
    "#     print(loss)\n",
    "\n",
    "# # On va voir à quel point on est correcte : \n",
    "# correct = 0\n",
    "# total = 0\n",
    "\n",
    "# with torch.no_grad():       # On ne veut pas des gradient ici on va juste regarder si on a bon ou pas sur la valeur avec le plus de proba\n",
    "#     for data in testset:\n",
    "#         X, y = data\n",
    "#         output = net(X.view(-1,784))\n",
    "#         #print(output)\n",
    "#         for idx, i in enumerate(output):\n",
    "#             #print(torch.argmax(i), y[idx])\n",
    "#             if torch.argmax(i) == y[idx]:\n",
    "#                 correct += 1\n",
    "#             total += 1\n",
    "\n",
    "# print(\"Accuracy: \", round(correct/total, 3))    # On arrondi la précision\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Afficher la première image\n",
    "# plt.imshow(X[0].view(28,28))\n",
    "# plt.show()\n",
    "\n",
    "# # Afficher notre prédiction (avec la proba la + élévé) de notre modèle\n",
    "# print(torch.argmax(net(X[0].view(-1,784))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
